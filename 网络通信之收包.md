[网络通信之收包](https://ty-chen.github.io/linux-kernel-tcp-receive/)

### 网卡驱动层：通过 NAPI（New API）或中断机制向内核提交数据包。
NAPI:
网络吞吐量比较大的时候，网络包的到达会十分频繁。这个时候，如果非常频繁地去触发中断，会造成频繁的上下文切换，带来极大的开销。因此硬件处理厂商设计了一种机制，就是当一些网络包到来触发了中断，内核处理完这些网络包之后，我们可以先进入主动轮询 poll 网卡的方式主动去接收到来的网络包。如果一直有，就一直处理，等处理告一段落，就返回干其他的事情。当再有下一批网络包到来的时候，再中断，再轮询 poll。这样就会大大减少中断的数量，提升网络处理的效率，这种处理方式我们称为 NAPI。

网卡被激活的时候调用ice_open(){
	注册硬件的中断处理函数（中断处理函数调用__napi_schedule(){}）
}，
__napi_schedule() 处于中断处理的关键部分，在被调用的时候，中断是暂时关闭的。处理网络包是个复杂的过程，需要到中断处理的延迟处理部分执行，所以 ____napi_schedule() 将当前设备放到 struct softnet_data 结构的 poll_list 里面，说明在延迟处理部分可以接着处理这个 poll_list 里面的网络设备。然后 ____napi_schedule() 触发一个软中断 NET_RX_SOFTIRQ，通过软中断触发中断处理的延迟处理部分，也是常用的手段。

中断 NET_RX_SOFTIRQ 对应的中断处理函数是 net_rx_action()

sd->poll_list用于网络包接收
从 poll_list 里面取出有网络包到达的设备，然后调用 napi_poll() 来轮询这些设备，napi_poll() 会调用最初设备初始化的时候注册的 poll 函数，对于 ixgb_driver对应的函数是 ixgb_clean() //在probe的时候注册的

ixgb_check_copybreak() 函数将 buffer_info 里面的内容拷贝到 struct sk_buff *skb，从而可以作为一个网络包进行后续的处理，然后调用 netif_receive_skb()进入MAC层继续进行收包的解析处理。

### MAC层
从 netif_receive_skb() 函数开始，我们就进入了内核的网络协议栈。接下来的调用链为：netif_receive_skb()->netif_receive_skb_internal()->__netif_receive_skb()->__netif_receive_skb_core()。在 __netif_receive_skb_core() 中，我们先是处理了二层的一些逻辑，如对于 VLAN 的处理，如果不是则调用deliver_ptype_list_skb() 在一个协议列表中逐个匹配在网络包 struct sk_buff 里面定义的 skb->protocol，该变量表示三层使用的协议类型。

无论是VLAN还是普通的包，最后的发送均会调用deliver_skb()，该函数会调用协议定义好的函数进行网络层解析。对于IP协议即为ip_rcv()。

*网卡硬件支持MAC地址过滤，检查MAC地址是否为本机或广播地址以及进行CRC校验*

### 网络层
ip_rcv(){
	ip_rcv_finish(){
	//ip_rcv_finish() 首先调用ip_rcv_finish_core()，该函数会先检测是否为广播、组播，如果不是则得到网络包对应的路由表，然后调用 dst_input()，在 dst_input() 中，调用的是 struct rtable 的成员的 dst 的 input() 函数。在 rt_dst_alloc() 中，我们可以看到input 函数指向的是 ip_local_deliver()。
	}
}
进入ip_local_deliver()意味着从PREROUTING确认进入本机处理，所以进入了状态INPUT，如果 IP 层进行了分段，则进行重新的组合。接下来就是我们熟悉的 NF_HOOK。在经过 iptables 规则处理完毕后，会调用 ip_local_deliver_finish()。
ip_local_deliver_finish()首先调用__skb_pull()从sk_buff中取下一个，接着调用ip_protocol_deliver_rcu()，该函数会从inet_protos[protocol]中找寻对应的处理函数进一步对收到的数据包进行解析。对应TCP的是tcp_v4_rcv()，UDP则是udp_rcv()。
 - ​TCP：处理序列号、确认机制、流量控制、拥塞控制，完成连接建立（三次握手）、数据分段重组。
​ - UDP：直接无连接传输，仅校验端口号和长度。

*NAT转换也是在网络层完成的*

### 五. 传输层
tcp_v4_rcv()

将数据包转发到对应进程的监听端口

通过 epoll、kqueue 或 select 等机制管理多个套接字（Socket）。

​查找连接（四元组匹配）​：
- 根据目的 IP (dst_ip)、目的端口 (dst_port)、源 IP (src_ip)、源端口 (src_port) 组成的 ​四元组，在 tcp_hashinfo 的哈希表中查找对应的 struct sock（套接字）。
- 如果存在已建立的连接（如 ESTABLISHED 状态），则直接将数据包加入该连接的接收队列。
- 如果是 SYN 包（建立新连接），则触发 tcp_v4_connect() 处理。
数据包队列入队：
- 找到的 struct sock 的 sk_receive_queue 队列中追加 skb。
- 唤醒等待读取数据的进程（通过 sk_wake_up 触发软中断）。

####套接字的注册与查找
​**(1) 套接字注册**
当进程调用 bind() 绑定端口时：
- ​TCP：在 tcp_hashinfo 中为 (port, net)（网络命名空间）注册 struct sock。
- ​UDP：在 udp_hashinfo 中为 (port, net) 注册 struct sock。
- ​哈希冲突解决：使用链表或红黑树存储同一端口/网络的多个套接字。

#### 应用层
- 通过套接字（Socket）将数据传递给目标进程。
- 常见服务绑定方式：inetd、systemd 监听端口，或进程主动调用 bind()/listen()。

### 六. 套接字层
当接收的网络包进入各种队列之后，接下来我们就要等待用户进程去读取它们了。读取一个 socket，就像读取一个文件一样，读取 socket 的文件描述符，通过 read 系统调用。read 系统调用对于一个文件描述符的操作，大致过程都是类似的，在文件系统那一节，我们已经详细解析过。最终它会调用到用来表示一个打开文件的结构 stuct file 指向的 file_operations 操作。
sock_recvmsg()实际调用sock_recvmmsg_nosec()，该函数会调用套接字对应的读操作，即inet_recvmsg()。
inet_recvmsg()会调用协议对应的读操作，即tcp_recvmsg()进行读操作。

## 关键优化技术
- ​零拷贝（Zero-Copy）​：直接在内核空间处理数据，减少 CPU 和内存占用（如 splice()、vmsplice()）。
- ​RSS（Receive Side Scaling）​：多核环境下将数据包分发给不同 CPU 核处理。
- ​XDP/eBPF：在网络层实现高效的数据包过滤或处理（无需进入内核协议栈）。

## NAIP
```c
static int e1000e_poll(struct napi_struct *napi, int budget)
{
	struct e1000_adapter *adapter = container_of(napi, struct e1000_adapter,
						     napi);
	struct e1000_hw *hw = &adapter->hw;
	struct net_device *poll_dev = adapter->netdev;
	int tx_cleaned = 1, work_done = 0;

	adapter = netdev_priv(poll_dev);

	//在未启用MSI-X或中断掩码冲突时，同时清理发送队列，避免发送完成事件堆积。
	if (!adapter->msix_entries ||
	    (adapter->rx_ring->ims_val & adapter->tx_ring->ims_val))
		tx_cleaned = e1000_clean_tx_irq(adapter->tx_ring);

	adapter->clean_rx(adapter->rx_ring, &work_done, budget);

	if (!tx_cleaned || work_done == budget)
		return budget;

	/* Exit the polling mode, but don't re-enable interrupts if stack might
	 * poll us due to busy-polling
	 */
	if (likely(napi_complete_done(napi, work_done))) {
		if (adapter->itr_setting & 3)
		//根据负载动态调整中断频率
			e1000_set_itr(adapter);
		if (!test_bit(__E1000_DOWN, &adapter->state)) {
			if (adapter->msix_entries)
			//仅在设备未关闭（!__E1000_DOWN）且使用MSI-X时，精准使能接收中断（通过IMS寄存器），减少无关中断触发。
				ew32(IMS, adapter->rx_ring->ims_val);
			else
				e1000_irq_enable(adapter);
		}
	}

	return work_done;
}
```
在bring up netdev的时候设置清理收包队列函数，分配收包缓冲区
```c
void e1000e_up(struct e1000_adapter *adapter)
{
	/* hardware has been reset, we need to reload some things */
	e1000_configure(adapter);

	clear_bit(__E1000_DOWN, &adapter->state);

	if (adapter->msix_entries)
		e1000_configure_msix(adapter);
	e1000_irq_enable(adapter);

	/* Tx queue started by watchdog timer when link is up */

	e1000e_trigger_lsc(adapter);
}
```

```c
static void e1000_configure(struct e1000_adapter *adapter)
{
	struct e1000_ring *rx_ring = adapter->rx_ring;

	e1000e_set_rx_mode(adapter->netdev);

	e1000_restore_vlan(adapter);
	e1000_init_manageability_pt(adapter);

	e1000_configure_tx(adapter);

	if (adapter->netdev->features & NETIF_F_RXHASH)
		e1000e_setup_rss_hash(adapter);
	e1000_setup_rctl(adapter);
	e1000_configure_rx(adapter);
	adapter->alloc_rx_buf(rx_ring, e1000_desc_unused(rx_ring), GFP_KERNEL);
}
```

```c
static bool e1000_clean_rx_irq(struct e1000_ring *rx_ring, int *work_done,
			       int work_to_do)
{
	struct e1000_adapter *adapter = rx_ring->adapter;
	struct net_device *netdev = adapter->netdev;
	struct pci_dev *pdev = adapter->pdev;
	struct e1000_hw *hw = &adapter->hw;
	union e1000_rx_desc_extended *rx_desc, *next_rxd;
	struct e1000_buffer *buffer_info, *next_buffer;
	u32 length, staterr;
	unsigned int i;
	int cleaned_count = 0;
	bool cleaned = false;
	unsigned int total_rx_bytes = 0, total_rx_packets = 0;

	i = rx_ring->next_to_clean;
	rx_desc = E1000_RX_DESC_EXT(*rx_ring, i);
	staterr = le32_to_cpu(rx_desc->wb.upper.status_error);
	buffer_info = &rx_ring->buffer_info[i];

	while (staterr & E1000_RXD_STAT_DD) { //当描述符的 DD（Descriptor Done）标志被置位时，表示该描述符对应的数据包已由硬件处理完成。适用于一次中断可能触发多个数据包处理的场景。
		struct sk_buff *skb;

		if (*work_done >= work_to_do)
			break;
		(*work_done)++;
		dma_rmb();	/* read descriptor and rx_buffer_info after status DD */

		//把skb指向buffuer中skb的地址，然后把buffer中skb的指针设置为NULL
		//问题：内核协议栈可以直接处理skb指向的地址吗？ buffer中如果有新的数据包过来，怎么存到skb中？
		skb = buffer_info->skb;
		buffer_info->skb = NULL;

		prefetch(skb->data - NET_IP_ALIGN);

		i++;
		if (i == rx_ring->count)
			i = 0;
		next_rxd = E1000_RX_DESC_EXT(*rx_ring, i);
		prefetch(next_rxd);

		next_buffer = &rx_ring->buffer_info[i];

		cleaned = true;
		cleaned_count++;
		**dma_unmap_single**(&pdev->dev, buffer_info->dma,
				 adapter->rx_buffer_len, DMA_FROM_DEVICE);//释放由硬件写入的DMA缓冲区，允许CPU访问数据
		buffer_info->dma = 0;//清空skb和DMA映射，准备复用或分配新缓冲区

		length = le16_to_cpu(rx_desc->wb.upper.length);

		/* !EOP means multiple descriptors were used to store a single
		 * packet, if that's the case we need to toss it.  In fact, we
		 * need to toss every packet with the EOP bit clear and the
		 * next frame that _does_ have the EOP bit set, as it is by
		 * definition only a frame fragment
		 */
		if (unlikely(!(staterr & E1000_RXD_STAT_EOP)))
			adapter->flags2 |= FLAG2_IS_DISCARDING;
		//若数据包跨多个描述符（EOP=0），则标记为丢弃（防止碎片包污染协议栈）。
		if (adapter->flags2 & FLAG2_IS_DISCARDING) {
			/* All receives must fit into a single buffer */
			e_dbg("Receive packet consumed multiple buffers\n");
			/* recycle */
			buffer_info->skb = skb;
			if (staterr & E1000_RXD_STAT_EOP)
				adapter->flags2 &= ~FLAG2_IS_DISCARDING;
			goto next_desc;
		}

		if (unlikely((staterr & E1000_RXDEXT_ERR_FRAME_ERR_MASK) &&
			     !(netdev->features & NETIF_F_RXALL))) {//若网卡不支持接收所有错误包（NETIF_F_RXALL 未启用），则丢弃错误数据包。
			/* recycle */
			buffer_info->skb = skb;
			goto next_desc;
		}

		/* adjust length to remove Ethernet CRC */
		if (!(adapter->flags2 & FLAG2_CRC_STRIPPING)) {
			/* If configured to store CRC, don't subtract FCS,
			 * but keep the FCS bytes out of the total_rx_bytes
			 * counter
			 */
			if (netdev->features & NETIF_F_RXFCS)
				total_rx_bytes -= 4;
			else
				length -= 4;
		}

		total_rx_bytes += length;
		total_rx_packets++;

		/* code added for copybreak, this should improve
		 * performance for small packets with large amounts
		 * of reassembly being done in the stack
		 */
		if (length < copybreak) {//小数据包优化（copybreak）：对小于 copybreak（通常 64~128 字节）的小包直接分配新 skb，避免旧 skb 的内存碎片问题。
			struct sk_buff *new_skb =
				napi_alloc_skb(&adapter->napi, length);
			if (new_skb) {
				skb_copy_to_linear_data_offset(new_skb,
							       -NET_IP_ALIGN,
							       (skb->data -
								NET_IP_ALIGN),
							       (length +
								NET_IP_ALIGN));
				/* save the skb in buffer_info as good */
				buffer_info->skb = skb;
				skb = new_skb;
			}
			/* else just continue with the old one */
		}
		/* end copybreak code */
		skb_put(skb, length);

		/* Receive Checksum Offload */
		e1000_rx_checksum(adapter, staterr, skb);

		e1000_rx_hash(netdev, rx_desc->wb.lower.hi_dword.rss, skb);

		e1000_receive_skb(adapter, netdev, skb, staterr,//将处理后的 skb 传递给协议栈
				  rx_desc->wb.upper.vlan);

next_desc:
		rx_desc->wb.upper.status_error &= cpu_to_le32(~0xFF);

		/* return some buffers to hardware, one at a time is too slow */
		if (cleaned_count >= E1000_RX_BUFFER_WRITE) {
			adapter->**alloc_rx_buf**(rx_ring, cleaned_count,
					      GFP_ATOMIC);//根据空闲描述符数量预分配新缓冲区，避免接收队列耗尽。
			cleaned_count = 0;
		}

		/* use prefetched values */
		rx_desc = next_rxd;
		buffer_info = next_buffer;

		staterr = le32_to_cpu(rx_desc->wb.upper.status_error);
	}
	rx_ring->next_to_clean = i;

	cleaned_count = e1000_desc_unused(rx_ring);
	if (cleaned_count)
		adapter->alloc_rx_buf(rx_ring, cleaned_count, GFP_ATOMIC);

	adapter->total_rx_bytes += total_rx_bytes;
	adapter->total_rx_packets += total_rx_packets;
	return cleaned;
}
```

```c
static void e1000_alloc_rx_buffers(struct e1000_ring *rx_ring,
				   int cleaned_count, gfp_t gfp)
{
	struct e1000_adapter *adapter = rx_ring->adapter;
	struct net_device *netdev = adapter->netdev;
	struct pci_dev *pdev = adapter->pdev;
	union e1000_rx_desc_extended *rx_desc;
	struct e1000_buffer *buffer_info;
	struct sk_buff *skb;
	unsigned int i;
	unsigned int bufsz = adapter->rx_buffer_len;

	i = rx_ring->next_to_use;
	buffer_info = &rx_ring->buffer_info[i];

	while (cleaned_count--) {
		skb = buffer_info->skb;
		if (skb) {
			skb_trim(skb, 0);
			goto map_skb;
		}

		skb = __netdev_alloc_skb_ip_align(netdev, bufsz, gfp);
		if (!skb) {
			/* Better luck next round */
			adapter->alloc_rx_buff_failed++;
			break;
		}

		buffer_info->skb = skb;
map_skb:
		buffer_info->dma = **dma_map_single**(&pdev->dev, skb->data,
						  adapter->rx_buffer_len,
						  DMA_FROM_DEVICE);
		if (dma_mapping_error(&pdev->dev, buffer_info->dma)) {
			dev_err(&pdev->dev, "Rx DMA map failed\n");
			adapter->rx_dma_failed++;
			break;
		}

		rx_desc = E1000_RX_DESC_EXT(*rx_ring, i);
		rx_desc->read.buffer_addr = cpu_to_le64(buffer_info->dma);

		if (unlikely(!(i & (E1000_RX_BUFFER_WRITE - 1)))) {
			/* Force memory writes to complete before letting h/w
			 * know there are new descriptors to fetch.  (Only
			 * applicable for weak-ordered memory model archs,
			 * such as IA-64).
			 */
			wmb();
			if (adapter->flags2 & FLAG2_PCIM2PCI_ARBITER_WA)
				e1000e_update_rdt_wa(rx_ring, i);
			else
				writel(i, rx_ring->tail);
		}
		i++;
		if (i == rx_ring->count)
			i = 0;
		buffer_info = &rx_ring->buffer_info[i];
	}

	rx_ring->next_to_use = i;
}
```

### 网卡收包过程
1. CPU去准备descriptor以及每一个descriptor所指向的buffer的地址。

2. 硬件去读收包descriptor并拿到它的buffer的地址。

3. 硬件把收到的包写到buffer地址中并更新descriptor。

4. CPU再去读收包descriptor。

代码中实现的是最后一步CPU去读descriptor以及准备descriptor和DMA buffer的过程。

### 网卡发包过程
1. CPU先去准备要发送的数据包，然后写TX descriptor。

2. 网卡去读TX descriptor拿到buffer的地址，再从buffer的地址中去读到要发送的包。

3. 网卡去写TX descriptor。

4. CPU再去读TX descriptor。